{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Primary Keys are considered unique.\n",
    "- Any type of database can be used. (used MySQL)\n",
    "- Error logging is at API retrieval step\n",
    "- 'timestamp' column from API == 'IMPORT_DATE' column on pdf file\n",
    "- Columns within DB must have the same name as on what's on the pdf file\n",
    "- Columns not listed within the sample pdf are dropped.\n",
    "- This is with the assumption that DB tables already exists. (use create_db.py to create tables in MySQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"root\"\n",
    "password = \"root\"\n",
    "host = \"localhost\"\n",
    "database = \"tzdb\"\n",
    "port = \"3306\"\n",
    "engine = None\n",
    "tbl_tzdb_timezones = \"tzdb_timezones\"\n",
    "tbl_tzdb_zone_details = \"tzdb_zone_details\"\n",
    "tbl_tzdb_error_log = \"tzdb_error_log\"\n",
    "key = \"RTMQTUPHJ22S\"\n",
    "\n",
    "tzdb_timezones_url = \"http://api.timezonedb.com/v2.1/list-time-zone\"\n",
    "tzdb_timezones_params = {\n",
    "    \"key\": key,\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "tzdb_zone_details_url = \"http://api.timezonedb.com/v2.1/get-time-zone\"\n",
    "tzdb_zone_details_params = {\n",
    "    \"key\": key,\n",
    "    \"format\": \"json\",\n",
    "    \"by\": \"position\",\n",
    "    \"lat\": 40.689247,\n",
    "    \"lng\": -74.044502\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error_to_db(msg):\n",
    "    timestamp = str(datetime.datetime.now())\n",
    "    data_error = [[timestamp, msg]]\n",
    "    df = pd.DataFrame(data=data_error, columns=['ERROR_DATE', 'ERROR_MESSAGE'])\n",
    "    df.to_sql(con=engine, name=tbl_tzdb_error_log, if_exists='append', index=False)\n",
    "    return print(f\"Error has been logged to '{tbl_tzdb_error_log}' table.\")\n",
    "\n",
    "def connect_to_api(url: str, params: dict):\n",
    "    try:\n",
    "        response = requests.get(url, params)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            msg = f\"{response.status_code} {response.raise_for_status()}\"\n",
    "            print(msg)\n",
    "            log_error_to_db(msg)\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        msg = f\"HTTP Error: {errh}\"\n",
    "        print(msg)\n",
    "        log_error_to_db(msg)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        msg = f\"Connection Error: {errc}\"\n",
    "        print(msg)\n",
    "        log_error_to_db(msg)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        msg = f\"Timeout Error: {errt}\"\n",
    "        print(msg)\n",
    "        log_error_to_db(msg)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        msg = f\"Unhandled Error: {err}\"\n",
    "        print(msg)\n",
    "        log_error_to_db(msg)\n",
    "    \n",
    "def get_api_dataframe(url: str, params: dict):\n",
    "    response = connect_to_api(url, params)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    if data[\"status\"].upper() == \"FAILED\":\n",
    "        return print(f\"Error: {data['message']} URL and PARAMS mismatch.\")\n",
    "    \n",
    "    if \"get\" in url:\n",
    "        df = pd.DataFrame([data])\n",
    "        return df\n",
    "    \n",
    "    if \"list\" in url:\n",
    "        df = pd.DataFrame(data[\"zones\"])\n",
    "        return df\n",
    "    \n",
    "    return (\"Please provide a valid API endpoint.\")\n",
    "\n",
    "def convert_datetime_col(df):\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).dt.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "    return df\n",
    "\n",
    "def get_db_connection():\n",
    "    return create_engine(url=f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "def get_rows_to_add(df_out, df_in, tbl_name):\n",
    "    merge = pd.merge(df_out, df_in, on=['ZONENAME', 'ZONESTART', 'ZONEEND'], how='outer', indicator='exists_yes_no')\n",
    "    df = merge.loc[merge['exists_yes_no'] == 'right_only']\n",
    "    df = df[df.columns.drop(list(df.filter(regex='_x')))]\n",
    "    if len(df) > 0:\n",
    "        print(f\"Table '{tbl_name}' has been updated! {len(df)} new row(s) added.\")\n",
    "    else:\n",
    "        print(f\"Table '{tbl_name}' remains the same! No additional row(s) added.\")\n",
    "    return df\n",
    "\n",
    "def clean_zone_details_df(df):\n",
    "    df = df.drop('exists_yes_no', axis=1)\n",
    "    col_order = ['COUNTRYCODE', 'COUNTRYNAME', 'ZONENAME', 'GMTOFFSET', 'DST', 'ZONESTART', 'ZONEEND', 'IMPORT_DATE']\n",
    "    true_col_names = {\n",
    "        'COUNTRYCODE_y':'COUNTRYCODE',\n",
    "        'COUNTRYNAME_y':'COUNTRYNAME',\n",
    "        'ZONENAME_y':'ZONENAME',\n",
    "        'GMTOFFSET_y':'GMTOFFSET',\n",
    "        'DST_y':'DST',\n",
    "        'ZONESTART_y':'ZONESTART',\n",
    "        'ZONEEND_y':'ZONEEND',\n",
    "        'IMPORT_DATE_y':'IMPORT_DATE'\n",
    "    }\n",
    "    df = df.rename(columns=true_col_names) #rename columns\n",
    "    df = df.reindex(columns=col_order) #reorder columns\n",
    "    return df\n",
    "\n",
    "def create_timezone_table(url: str, params: dict):\n",
    "    df = get_api_dataframe(url, params)\n",
    "    df = convert_datetime_col(df)\n",
    "    df.rename(columns= {\n",
    "        'countryCode':'COUNTRYCODE',\n",
    "        'countryName':'COUNTRYNAME',\n",
    "        'zoneName':'ZONENAME',\n",
    "        'gmtOffset':'GMTOFFSET',\n",
    "        'timestamp':'IMPORT_DATE'\n",
    "        }, inplace=True)\n",
    "    return df\n",
    "\n",
    "def create_zone_details_table(url: str, params: dict):\n",
    "    df = get_api_dataframe(url, params)\n",
    "    df = convert_datetime_col(df)\n",
    "    df.drop(['status', 'message', 'regionName', 'cityName', 'abbreviation', 'nextAbbreviation', 'formatted'], axis=1, inplace=True)\n",
    "    df.rename(columns= {\n",
    "        'countryCode':'COUNTRYCODE',\n",
    "        'countryName':'COUNTRYNAME',\n",
    "        'zoneName':'ZONENAME',\n",
    "        'gmtOffset':'GMTOFFSET',\n",
    "        'dst':'DST',\n",
    "        'zoneStart':'ZONESTART',\n",
    "        'zoneEnd':'ZONEEND',\n",
    "        'timestamp':'IMPORT_DATE'\n",
    "        }, inplace=True)\n",
    "    return df\n",
    "\n",
    "def select_db_table(tbl_name, engine):\n",
    "    sql = f\"SELECT * FROM {tbl_name}\"\n",
    "    df = pd.read_sql(sql, con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Start . . .\")\n",
    "        # Run a GET request from API endpoints to create dataframe\n",
    "        df_timezone_table = create_timezone_table(tzdb_timezones_url, tzdb_timezones_params)\n",
    "        df_zone_details_stage = create_zone_details_table(tzdb_zone_details_url, tzdb_zone_details_params)\n",
    "        \n",
    "        # Write (re-write) Timezone Table to DB\n",
    "        df_timezone_table.to_sql(con=engine, name=tbl_tzdb_timezones, if_exists='replace', index=False)\n",
    "        print(f\"Table '{tbl_tzdb_timezones}' has been updated!\")\n",
    "\n",
    "        # FOR TESTING ONLY - dummy data for STAGE dataframe to test appending of data logic\n",
    "        # df_zone_details_stage = pd.read_csv(\"test_zone_details.csv\") \n",
    "\n",
    "        # Read 'tzdb_zone_details' table from DB\n",
    "        df_zone_details = select_db_table(tbl_tzdb_zone_details, engine)\n",
    "\n",
    "        # Compare STAGE dataframe vs what's on db, fix column names and arrangement, then add row(s) from STAGE if row(s) does not exist in db\n",
    "        df_rows_to_add = get_rows_to_add(df_zone_details, df_zone_details_stage, tbl_tzdb_zone_details)\n",
    "        df_rows_to_add = clean_zone_details_df(df_rows_to_add)\n",
    "\n",
    "        # Write contents of API directly if \"tzdb_zone_details\" table is empty\n",
    "        if len(df_zone_details) == 0:\n",
    "            df_zone_details_stage.to_sql(con=engine, name=tbl_tzdb_zone_details, if_exists='replace', index=False)\n",
    "        else:\n",
    "            df_rows_to_add.to_sql(con=engine, name=tbl_tzdb_zone_details, if_exists='append', index=False)\n",
    "\n",
    "        print(\"End . . .\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    engine = get_db_connection()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
